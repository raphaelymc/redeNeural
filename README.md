# Projeto: ImplementaÃ§Ã£o de Rede Neural Artificial (RNA) para ClassificaÃ§Ã£o BinÃ¡ria

## ğŸ“ DescriÃ§Ã£o
Este projeto Ã© uma implementaÃ§Ã£o fundamental de uma Rede Neural Artificial (RNA), desenvolvida do zero em Python como parte dos estudos em Fundamentos de InteligÃªncia Artificial. O objetivo foi simular o aprendizado e demonstrar a compreensÃ£o prÃ¡tica do mecanismo de ajuste de pesos (sinapses) por meio da retropropagaÃ§Ã£o. A rede foi configurada para resolver um problema bÃ¡sico de classificaÃ§Ã£o binÃ¡ria.

## ğŸ’» Stack TecnolÃ³gico
* **Linguagem:** Python
* **Biblioteca NumPy:** Essencial para lidar com todas as operaÃ§Ãµes matriciais necessÃ¡rias, como o produto interno no *feedforward* e o cÃ¡lculo do gradiente no *backpropagation*.
* **Biblioteca Matplotlib:** Utilizada para visualizaÃ§Ã£o e registro da convergÃªncia do erro durante o treinamento.
* **Ambiente:** Desenvolvido no Visual Studio Code (VS Code).

## âš™ï¸ Arquitetura e Metodologia
A arquitetura consiste em uma rede simples de uma Ãºnica camada:

* **FunÃ§Ã£o de AtivaÃ§Ã£o:** UtilizaÃ§Ã£o da **FunÃ§Ã£o Sigmoide** e sua derivada. A Sigmoide comprime a saÃ­da entre 0 e 1, ideal para classificaÃ§Ã£o de probabilidade.
* **Treinamento (Backpropagation):** O loop de treinamento foi executado por **10.000 Ã©pocas**. Em cada iteraÃ§Ã£o, a rede realizou a propagaÃ§Ã£o para frente (*feedforward*) e utilizou o erro para retropropagar e calcular o ajuste necessÃ¡rio nos pesos (*backpropagation*).

## ğŸ“Š Resultados e AnÃ¡lise

### 1. ConvergÃªncia do Erro
A convergÃªncia do erro Ã© a evidÃªncia mais forte do aprendizado. O erro mÃ©dio, que se inicia alto, caiu drasticamente nas primeiras Ã©pocas, estabilizando-se em um valor muito prÃ³ximo de zero. Isso demonstra que a rede convergiu de forma rÃ¡pida e estÃ¡vel.
## ğŸ“‰ Resultado da ConvergÃªncia (GrÃ¡fico de Erro)
O grÃ¡fico abaixo demonstra a evoluÃ§Ã£o do erro mÃ©dio da rede neural ao longo das Ã©pocas de treinamento, mostrando a convergÃªncia do modelo.

![GrÃ¡fico de ConvergÃªncia da RNA](erro_convergencia.png)

### 2. SaÃ­da Final e PrecisÃ£o
A saÃ­da final confirma a precisÃ£o da classificaÃ§Ã£o. Para as entradas onde a resposta esperada era 0, a rede produziu valores como **0.01**, e para as entradas esperadas como 1, produziu valores de alta confianÃ§a (**0.98** e **0.89**).

## ğŸ”‘ ConclusÃ£o do Estudo
O exercÃ­cio prÃ¡tico atingiu seu objetivo, fornecendo uma base sÃ³lida sobre o mecanismo de aprendizado. Observar o erro caindo e os pesos se ajustando reforÃ§a a compreensÃ£o de que o aprendizado de mÃ¡quina Ã©, essencialmente, um processo de otimizaÃ§Ã£o matemÃ¡tica. Este projeto serve como uma base sÃ³lida para o desenvolvimento de redes neurais mais complexas no futuro.
